{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv('/Users/asalzooashkiany/Documents/-DS-Midterm-Project./data/my_dataframe.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['last_update_date'] = pd.to_datetime(df['last_update_date'])\n",
    "df['list_date'] = pd.to_datetime(df['list_date'])\n",
    "df['Sold Date'] = pd.to_datetime(df['Sold Date'])\n",
    "\n",
    "\n",
    "# For last_update_date\n",
    "df['last_update_year'] = df['last_update_date'].dt.year\n",
    "df['last_update_month'] = df['last_update_date'].dt.month\n",
    "df['last_update_day'] = df['last_update_date'].dt.day\n",
    "\n",
    "# For list_date\n",
    "df['list_date_year'] = df['list_date'].dt.year\n",
    "df['list_date_month'] = df['list_date'].dt.month\n",
    "df['list_date_day'] = df['list_date'].dt.day\n",
    "\n",
    "\n",
    "df['sold_year'] = df['Sold Date'].dt.year\n",
    "df['sold_month'] = df['Sold Date'].dt.month\n",
    "df['sold_day'] = df['Sold Date'].dt.day\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['last_update_date', 'list_date', 'Sold Date'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>price_reduced_amount</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Year Built</th>\n",
       "      <th>Sold Price</th>\n",
       "      <th>Baths Full</th>\n",
       "      <th>Lot SqFt</th>\n",
       "      <th>Baths</th>\n",
       "      <th>Beds</th>\n",
       "      <th>...</th>\n",
       "      <th>Tags Count</th>\n",
       "      <th>last_update_year</th>\n",
       "      <th>last_update_month</th>\n",
       "      <th>last_update_day</th>\n",
       "      <th>list_date_year</th>\n",
       "      <th>list_date_month</th>\n",
       "      <th>list_date_day</th>\n",
       "      <th>sold_year</th>\n",
       "      <th>sold_month</th>\n",
       "      <th>sold_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Harrisburg</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>345000.0</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>22651.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Harrisburg</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>196000.0</td>\n",
       "      <td>2.80429</td>\n",
       "      <td>2614.0</td>\n",
       "      <td>2.960836</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Harrisburg</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>205000.0</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>13504.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Harrisburg</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>295000.0</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2688.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Harrisburg</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>106000.0</td>\n",
       "      <td>2.80429</td>\n",
       "      <td>871.0</td>\n",
       "      <td>2.960836</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  price_reduced_amount        City         State  Year Built  \\\n",
       "0           0                   0.0  Harrisburg  Pennsylvania      2001.0   \n",
       "1           1                   0.0  Harrisburg  Pennsylvania      1900.0   \n",
       "2           2                   0.0  Harrisburg  Pennsylvania      1971.0   \n",
       "3           3                   0.0  Harrisburg  Pennsylvania      2013.0   \n",
       "4           4                   0.0  Harrisburg  Pennsylvania      1900.0   \n",
       "\n",
       "   Sold Price  Baths Full  Lot SqFt     Baths  Beds  ...  Tags Count  \\\n",
       "0    345000.0     2.00000   22651.0  2.000000   3.0  ...          17   \n",
       "1    196000.0     2.80429    2614.0  2.960836   3.0  ...           8   \n",
       "2    205000.0     2.00000   13504.0  2.000000   3.0  ...          12   \n",
       "3    295000.0     2.00000    2688.0  3.000000   3.0  ...          11   \n",
       "4    106000.0     2.80429     871.0  2.960836   3.0  ...           3   \n",
       "\n",
       "  last_update_year  last_update_month  last_update_day  list_date_year  \\\n",
       "0             2024                  1               17            2023   \n",
       "1             2024                  1               16            2023   \n",
       "2             2024                  1               13            2023   \n",
       "3             2024                  1               16            2023   \n",
       "4             2024                  1               13            2023   \n",
       "\n",
       "   list_date_month  list_date_day  sold_year  sold_month  sold_day  \n",
       "0               11             27       2024           1        16  \n",
       "1               11             23       2024           1        16  \n",
       "2               12             16       2024           1        12  \n",
       "3               10             24       2024           1        12  \n",
       "4               11             15       2024           1        12  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>price_reduced_amount</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Year Built</th>\n",
       "      <th>Sold Price</th>\n",
       "      <th>Baths Full</th>\n",
       "      <th>Lot SqFt</th>\n",
       "      <th>Baths</th>\n",
       "      <th>Beds</th>\n",
       "      <th>...</th>\n",
       "      <th>Tags Count</th>\n",
       "      <th>last_update_year</th>\n",
       "      <th>last_update_month</th>\n",
       "      <th>last_update_day</th>\n",
       "      <th>list_date_year</th>\n",
       "      <th>list_date_month</th>\n",
       "      <th>list_date_day</th>\n",
       "      <th>sold_year</th>\n",
       "      <th>sold_month</th>\n",
       "      <th>sold_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4359</th>\n",
       "      <td>6612</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>Hermitage</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>520000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12197.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  price_reduced_amount       City      State  Year Built  \\\n",
       "4359        6612               10000.0  Hermitage  Tennessee      2006.0   \n",
       "\n",
       "      Sold Price  Baths Full  Lot SqFt  Baths  Beds  ...  Tags Count  \\\n",
       "4359    520000.0         2.0   12197.0    2.0   3.0  ...          21   \n",
       "\n",
       "     last_update_year  last_update_month  last_update_day  list_date_year  \\\n",
       "4359             2024                  1                7            2023   \n",
       "\n",
       "      list_date_month  list_date_day  sold_year  sold_month  sold_day  \n",
       "4359               10             14       2024           1         5  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['City']== 'Hermitage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df[df['City']!= 'Hermitage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>price_reduced_amount</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Year Built</th>\n",
       "      <th>Sold Price</th>\n",
       "      <th>Baths Full</th>\n",
       "      <th>Lot SqFt</th>\n",
       "      <th>Baths</th>\n",
       "      <th>Beds</th>\n",
       "      <th>...</th>\n",
       "      <th>Tags Count</th>\n",
       "      <th>last_update_year</th>\n",
       "      <th>last_update_month</th>\n",
       "      <th>last_update_day</th>\n",
       "      <th>list_date_year</th>\n",
       "      <th>list_date_month</th>\n",
       "      <th>list_date_day</th>\n",
       "      <th>sold_year</th>\n",
       "      <th>sold_month</th>\n",
       "      <th>sold_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>2335</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>Galloway</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>271000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6098.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  price_reduced_amount      City State  Year Built  \\\n",
       "1563        2335                5000.0  Galloway  Ohio      1993.0   \n",
       "\n",
       "      Sold Price  Baths Full  Lot SqFt  Baths  Beds  ...  Tags Count  \\\n",
       "1563    271000.0         2.0    6098.0    3.0   3.0  ...          10   \n",
       "\n",
       "     last_update_year  last_update_month  last_update_day  list_date_year  \\\n",
       "1563             2023                 12               29            2023   \n",
       "\n",
       "      list_date_month  list_date_day  sold_year  sold_month  sold_day  \n",
       "1563               11             17       2023          12        29  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['City']== 'Galloway']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['City'] != 'Galloway']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='Sold Price')\n",
    "y = df['Sold Price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state= 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3733, 21)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 21)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import TargetEncoder\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unknown categories ['Tolleson'] in column 0 during transform",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39m# Make predictions\u001b[39;00m\n\u001b[1;32m     40\u001b[0m y_pred_train \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39mpredict(X_train)\n\u001b[0;32m---> 41\u001b[0m y_pred_test \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m     43\u001b[0m \u001b[39m# Assuming a classification task; adjust metrics for regression\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mLinear Regression\u001b[39m\u001b[39m'\u001b[39m:  \u001b[39m# Skip accuracy for Linear Regression\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/sklearn/pipeline.py:480\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    478\u001b[0m Xt \u001b[39m=\u001b[39m X\n\u001b[1;32m    479\u001b[0m \u001b[39mfor\u001b[39;00m _, name, transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(with_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 480\u001b[0m     Xt \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39mtransform(Xt)\n\u001b[1;32m    481\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mpredict(Xt, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpredict_params)\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:800\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    796\u001b[0m     \u001b[39m# ndarray was used for fitting or transforming, thus we only\u001b[39;00m\n\u001b[1;32m    797\u001b[0m     \u001b[39m# check that n_features_in_ is consistent\u001b[39;00m\n\u001b[1;32m    798\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_n_features(X, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 800\u001b[0m Xs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_transform(\n\u001b[1;32m    801\u001b[0m     X,\n\u001b[1;32m    802\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    803\u001b[0m     _transform_one,\n\u001b[1;32m    804\u001b[0m     fitted\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    805\u001b[0m     column_as_strings\u001b[39m=\u001b[39mfit_dataframe_and_transform_dataframe,\n\u001b[1;32m    806\u001b[0m )\n\u001b[1;32m    807\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_output(Xs)\n\u001b[1;32m    809\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m Xs:\n\u001b[1;32m    810\u001b[0m     \u001b[39m# All transformers are None\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:658\u001b[0m, in \u001b[0;36mColumnTransformer._fit_transform\u001b[0;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[1;32m    652\u001b[0m transformers \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m    653\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(\n\u001b[1;32m    654\u001b[0m         fitted\u001b[39m=\u001b[39mfitted, replace_strings\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, column_as_strings\u001b[39m=\u001b[39mcolumn_as_strings\n\u001b[1;32m    655\u001b[0m     )\n\u001b[1;32m    656\u001b[0m )\n\u001b[1;32m    657\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 658\u001b[0m     \u001b[39mreturn\u001b[39;00m Parallel(n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)(\n\u001b[1;32m    659\u001b[0m         delayed(func)(\n\u001b[1;32m    660\u001b[0m             transformer\u001b[39m=\u001b[39mclone(trans) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fitted \u001b[39melse\u001b[39;00m trans,\n\u001b[1;32m    661\u001b[0m             X\u001b[39m=\u001b[39m_safe_indexing(X, column, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[1;32m    662\u001b[0m             y\u001b[39m=\u001b[39my,\n\u001b[1;32m    663\u001b[0m             weight\u001b[39m=\u001b[39mweight,\n\u001b[1;32m    664\u001b[0m             message_clsname\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mColumnTransformer\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    665\u001b[0m             message\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(name, idx, \u001b[39mlen\u001b[39m(transformers)),\n\u001b[1;32m    666\u001b[0m         )\n\u001b[1;32m    667\u001b[0m         \u001b[39mfor\u001b[39;00m idx, (name, trans, column, weight) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(transformers, \u001b[39m1\u001b[39m)\n\u001b[1;32m    668\u001b[0m     )\n\u001b[1;32m    669\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    670\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mapply_async(batch, callback\u001b[39m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/sklearn/pipeline.py:876\u001b[0m, in \u001b[0;36m_transform_one\u001b[0;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_transform_one\u001b[39m(transformer, X, y, weight, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params):\n\u001b[0;32m--> 876\u001b[0m     res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    877\u001b[0m     \u001b[39m# if we have a weight for this transformer, multiply output\u001b[39;00m\n\u001b[1;32m    878\u001b[0m     \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/sklearn/pipeline.py:658\u001b[0m, in \u001b[0;36mPipeline.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    656\u001b[0m Xt \u001b[39m=\u001b[39m X\n\u001b[1;32m    657\u001b[0m \u001b[39mfor\u001b[39;00m _, _, transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter():\n\u001b[0;32m--> 658\u001b[0m     Xt \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39mtransform(Xt)\n\u001b[1;32m    659\u001b[0m \u001b[39mreturn\u001b[39;00m Xt\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:917\u001b[0m, in \u001b[0;36mOneHotEncoder.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[39m# validation of X happens in _check_X called by _transform\u001b[39;00m\n\u001b[1;32m    913\u001b[0m warn_on_unknown \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_unknown \u001b[39min\u001b[39;00m {\n\u001b[1;32m    914\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    915\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minfrequent_if_exist\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    916\u001b[0m }\n\u001b[0;32m--> 917\u001b[0m X_int, X_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transform(\n\u001b[1;32m    918\u001b[0m     X,\n\u001b[1;32m    919\u001b[0m     handle_unknown\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_unknown,\n\u001b[1;32m    920\u001b[0m     force_all_finite\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    921\u001b[0m     warn_on_unknown\u001b[39m=\u001b[39mwarn_on_unknown,\n\u001b[1;32m    922\u001b[0m )\n\u001b[1;32m    923\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_infrequent_categories(X_int, X_mask)\n\u001b[1;32m    925\u001b[0m n_samples, n_features \u001b[39m=\u001b[39m X_int\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:174\u001b[0m, in \u001b[0;36m_BaseEncoder._transform\u001b[0;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39mif\u001b[39;00m handle_unknown \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    170\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    171\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound unknown categories \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m in column \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m during transform\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(diff, i)\n\u001b[1;32m    173\u001b[0m     )\n\u001b[0;32m--> 174\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m    175\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     \u001b[39mif\u001b[39;00m warn_on_unknown:\n",
      "\u001b[0;31mValueError\u001b[0m: Found unknown categories ['Tolleson'] in column 0 during transform"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming X and y are already defined\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "categorical_features = ['City', 'State', 'Type']\n",
    "numerical_features = [col for col in X.columns if col not in categorical_features]\n",
    "\n",
    "# Preprocessors\n",
    "categorical_preprocessor = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "numerical_preprocessor = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())  # Scaling is beneficial for Linear Regression and SVM\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_preprocessor, categorical_features),\n",
    "        ('num', numerical_preprocessor, numerical_features)\n",
    "    ]\n",
    ")\n",
    "# Adjusted to use your defined feature lists\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('numeric', numeric_transform, numerical_features),\n",
    "    ('categorical', categorical_transform, categorical_features)\n",
    "])\n",
    "\n",
    "# Ensure the target variable y and the evaluation metrics are appropriate for each model\n",
    "\n",
    "# Models to evaluate, assuming a classification task (adjust as necessary)\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),  # Typically used for regression\n",
    "    'SVM': SVC(),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_train = pipeline.predict(X_train)\n",
    "    y_pred_test = pipeline.predict(X_test)\n",
    "    \n",
    "    # Assuming a classification task; adjust metrics for regression\n",
    "    if name != 'Linear Regression':  # Skip accuracy for Linear Regression\n",
    "        train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "        test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "        print(f\"Results for {name}:\")\n",
    "        print(f\"Training Accuracy: {train_accuracy}, Test Accuracy: {test_accuracy}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3733,) (3733,) (1600,) (1600,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_pred_train.shape, y_test.shape, y_pred_test.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook should include preliminary and baseline modeling.\n",
    "- Try as many different models as possible.\n",
    "- Don't worry about hyperparameter tuning or cross validation here.\n",
    "- Ideas include:\n",
    "    - linear regression\n",
    "    - support vector machines\n",
    "    - random forest\n",
    "    - xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models and fit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider what metrics you want to use to evaluate success.\n",
    "- If you think about mean squared error, can we actually relate to the amount of error?\n",
    "- Try root mean squared error so that error is closer to the original units (dollars)\n",
    "- What does RMSE do to outliers?\n",
    "- Is mean absolute error a good metric for this problem?\n",
    "- What about R^2? Adjusted R^2?\n",
    "- Briefly describe your reasons for picking the metrics you use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather evaluation metrics and compare results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STRETCH**\n",
    "\n",
    "Even with all the preprocessing we did in Notebook 1, you probably still have a lot of features. Are they all important for prediction?\n",
    "\n",
    "Investigate some feature selection algorithms (Lasso, RFE, Forward/Backward Selection)\n",
    "- Perform feature selection to get a reduced subset of your original features\n",
    "- Refit your models with this reduced dimensionality - how does performance change on your chosen metrics?\n",
    "- Based on this, should you include feature selection in your final pipeline? Explain\n",
    "\n",
    "Remember, feature selection often doesn't directly improve performance, but if performance remains the same, a simpler model is often preferrable. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform feature selection \n",
    "# refit models\n",
    "# gather evaluation metrics and compare to the previous step (full feature set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (test_env)",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
